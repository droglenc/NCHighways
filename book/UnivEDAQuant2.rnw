<<echo=FALSE, cache=FALSE, results='hide'>>=
set_parent('IntroStats.Rnw')
@

\chapter[Univ EDA Quantitative]{Univariate EDA - Quantitative} \label{chap:UnivEDAQuant2}
\begin{ChapObj}{\boxwidth}
  \textbf{Objectives:}
  \begin{Enumerate}
    \item Use graphs to describe the shape of a distribution,
    \item Use graphs to describe outliers in a distribution,
    \item Identify which summary statistics are appropriate in a given situation, and
    \item Construct an appropriate overall summary.
  \end{Enumerate}
\end{ChapObj}

\minitoc
\vspace{40pt}

\lettrine{A}{ univariate EDA for a quantitative variable} is concerned with describing the distribution of the values for that variable; i.e., describing what values occurred and how often those values occurred. Specifically, the distribution is described by four specific attributes:

\vspace{-12pt}
\begin{Enumerate}
  \item \textbf{shape} of the distribution,
  \item presence of \textbf{outliers},
  \item \textbf{center} of the distribution, and
  \item \textbf{dispersion} or spread of the distribution.
\end{Enumerate}
\vspace{-8pt}

Graphs are used to identify shape and the presence of outliers and to get a general feel for center and dispersion. Numerical summaries, however, are used to specifically describe center and dispersion of the data. Computing and constructing the required numerical and graphical summaries was described in \modref{chap:UnivEDAQuant1}. Those summaries are interpreted here to provide an overall description of the distribution of the quantitative variable

The same three data sets used in \modref{chap:UnivEDAQuant1} are used here.

\vspace{-12pt}
\begin{Itemize}
  \item Number of open pit mines in countries with open pit mines \tabrefp{tab:MineData}.
  \item Richter scale recordings for 15 major earthquakes \tabrefp{tab:EQData}.
  \item The number of days of ice cover at ice gauge station 9004 in Lake Superior.
\end{Itemize}

\section{Interpreting Shape}
A distribution has two tails -- a left-tail for smaller or more negative values and a right-tail for larger or more positive values \figrefp{fig:ShapeExamples1}. The relative appearance of these two tails is used to identify three different shapes of distributions -- symmetric, left-skewed, and right-skewed. If the left- and right-tail of a distribution are approximately equal in shape (length and height), then the distribution is said to be \textbf{symmetric} (or more specifically \textbf{approximately symmetric}). If the left-tail is stretched out or is longer and flatter than the right-tail, then the distribution is negatively- or \textbf{left-skewed}. If the right-tail is stretched out or is longer and flatter than the left-tail, then the distribution is positively- or \textbf{right-skewed}. The type of skew is defined by the longer tail; a longer right-tail means the distribution is right-skewed and a longer left-tail means it is left-skewed.

<<ShapeExamples1, echo=FALSE, fig.width=3*2.75, fig.height=2.75, out.width='.9\\linewidth', fig.cap="Examples of symmetric (left), left-skewed (center), and right-skewed (right) distributions.">>=
x <- seq(0,1,0.005)
symy <- dbeta(x,shape1=7,shape2=7)
righty <- dbeta(x,shape1=2,shape2=6)
lefty <- dbeta(x,shape1=6,shape2=2)

par(mfrow=c(1,3),mar=c(1.5,1.5,1.2,0.5),mgp=c(0.4,0,0),xaxt="n",yaxt="n",
    bty="l",yaxs="i",cex=1.05)
xlbl <- "Quantitative Variable"
ylbl <- "Frequency"
plot(symy~x,type="l",xlab=xlbl,ylab=ylbl,main="Symmetric",
     ylim=c(-0.02,1.1*max(symy)),lwd=2)
text(0.5,0.25*max(symy),"Left- and\n Right-tails\n look similar")
plot(lefty~x,type="l",xlab=xlbl,ylab=ylbl,main="Left-Skewed",
     ylim=c(-0.02,1.1*max(lefty)),lwd=2)
text(0.3,0.7*max(lefty),"Left-tail is flatter,\n more spread out.")
plot(righty~x,type="l",xlab=xlbl,ylab=ylbl,main="Right-Skewed",
     ylim=c(-0.02,1.1*max(righty)),lwd=2)
text(0.7,0.7*max(righty),"Right-tail is flatter,\n more spread out.")
@

\warn{The longer tail defines the type of skew.}

In practice, these labels form a continuum. For example, a perfectly symmetric distribution is rare. However, in the many cases of an asymmetric distribution, it is a fine line between calling the shape approximately symmetric or one of the skewed distributions. In addition, ``slightly'' or ``strongly'' may be used with ``skewed'' to distinguish whether the distribution is obviously skewed (i.e., ``strongly skewed'') or nearly symmetric (i.e., ``slightly skewed'').

\warn{Symmetric, left-skewed, and right-skewed descriptors are guides; many ``real'' distributions will not fall neatly into these categories.}

The shape of a distribution is most easily identified from a histogram. Histograms that are examples of each shape are in \figref{fig:ShapeExamples2}. For the sets of skewed distributions, the distributions are less strongly skewed from left-to-right.

<<ShapeExamples2, echo=FALSE, fig.width=10.5, fig.height=10.5, out.width='.7\\linewidth', fig.cap="Examples of approximately symmetric (top, red), left-skewed (middle, blue), and right-skewed (bottom, green) histograms. Note that the axes labels were removed to focus on the shape of the histograms.">>=
set.seed(1256)
n <- 1000
brks <- seq(0,1,0.1)
s1 <- rbeta(n,1,1)
s2 <- rbeta(n,3,3)
s3 <- rbeta(n,9,9)
l1 <- rbeta(n,3,1)
l2 <- rbeta(n,4,2)
l3 <- rbeta(n,9,3)
r1 <- rbeta(n,1,3)
r2 <- rbeta(n,2,4)
r3 <- rbeta(n,3,9)
par(mar=c(1,1,1,1),mgp=c(0.1,0,0),mfrow=c(3,3),xaxt="n",yaxt="n",cex=1.7)
hist(s1,xlim=c(0,1),ylab="Approx. Symmetric",xlab="",main="",breaks=brks,col="lightsalmon")
hist(s2,xlim=c(0,1),ylab="",xlab="",main="",breaks=brks,col="lightsalmon")
hist(s3,xlim=c(0,1),ylab="",xlab="",main="",breaks=brks,col="lightsalmon")
hist(l1,xlim=c(0,1),ylab="Left-Skewed",xlab="",main="",breaks=brks,col="lightblue1")
hist(l2,xlim=c(0,1),ylab="",xlab="",main="",breaks=brks,col="lightblue1")
hist(l3,xlim=c(0,1),ylab="",xlab="",main="",breaks=brks,col="lightblue1")
hist(r1,xlim=c(0,1),ylab="Right-Skewed",xlab="",main="",breaks=brks,col="lightgreen")
hist(r2,xlim=c(0,1),ylab="",xlab="",main="",breaks=brks,col="lightgreen")
hist(r3,xlim=c(0,1),ylab="",xlab="",main="",breaks=brks,col="lightgreen")
@

The shape of a distribution can also be determined from a boxplot. The relative length from the median to Q1 and the median to Q3 (i.e., the position of the median line in the box) indicates the shape of the distribution. If the distribution is left-skewed (i.e., lesser-valued individuals are ``spread out''; \figref{fig:BoxplotShape}-Right), then median-Q1 will be greater than Q3-median. In contrast, if the distribution is right-skewed (i.e., larger-valued individuals are spread out; \figref{fig:BoxplotShape}-Middle), then Q3-median will be greater than median-Q1. Thus, if the distribution is right-skewed, then the median will be closer to Q1 than to Q3; if the distribution is left-skewed, then the median will be closer to Q3 than to Q1; and if the distribution is approximately symmetric (\figref{fig:BoxplotShape}-Left), then the median will be in the middle of the box.

<<BoxplotShape, echo=FALSE, out.width='.25\\linewidth', fig.cap="Histograms and boxplots for several different shapes of distributions.">>=
par(mar=c(1,0.5,1,0.5),mgp=c(2.1,0.4,0),xaxt="n",yaxt="n",cex=1.2)
brks<-seq(-0.1,1.1,0.1)
hist(s2,main="Approx. Symmetric",xlab="",ylab="",breaks=brks,col="lightsalmon")
hist(l1,xlim=c(0.1,1),main="Left-Skewed",xlab="",ylab="",breaks=brks,col="lightblue")
text(0.3,125,"Left-tail flatter\n more spread out")
hist(r1,xlim=c(0,0.9),main="Right-Skewed",xlab="",ylab="",breaks=brks,col="lightgreen")
text(0.7,125,"Right-tail flatter\n more spread out")
boxplot(s2,range=0)
boxplot(l1,range=0)
text(1.2,median(l1),"Median",pos=4)
text(1.2,quantile(l1,0.25),"Q1",pos=4)
text(0.7,0.15,"Median-Q1\n greater than\n Q3-Median",pos=3)
boxplot(r1,range=0)
text(1.2,median(r1),"Median",pos=4)
text(1.2,quantile(r1,0.75),"Q3",pos=4)
text(0.7,0.6,"Q3-Median\n greater than\n Median-Q1",pos=3)
@

\warn{Even though shape can be described from a boxplot, it is always easier to describe shape from a histogram.}

\section{Interpreting Outliers}
An outlier is an individual whose value is widely separated from the main cluster of values in the sample. On histograms, outliers appear as bars that are separated from the main cluster of bars by ``white space'' or areas with no bars \figrefp{fig:OutlierExHist}. In general, outliers must be on the margins of the histogram, should be separated by one or two missing bars, and should only be one or two individuals.

<<OutlierExHist, echo=FALSE, fig.cap="Example histogram with an outlier to the right.">>=
par(mar=c(0.5,0.5,0.5,0.5),mgp=c(0,0.0,0),las=1,tcl=-0.2)
hist(c(rbeta(100,9,9),1.2),main="",xlab="",xaxt="n",ylab="",yaxt="n",col="gray90")
@

An outlier may occur as a result of human error in the sampling process. If this is the case, then the value should be corrected or removed. Other times an outlier may be an individual that was not part of the population of interest -- e.g., an adult animal that was sampled when only immature animals were being considered. In this case, the individual's value should be removed from the sample. Still other times, an outlier is part of the population and should generally not be removed from the sample. In fact you may wish to highlight an outlier as an interesting observation! Regardless, it is important that you construct a histogram to determine if outliers are present or not.

Don't let outliers completely influence how you define the shape of a distribution. For example, if the main cluster of values is approximately symmetric and there is one outlier to the right of the main cluster (as illustrated in \figref{fig:OutlierExHist}), \textbf{DON'T} call the distribution right-skewed. You should describe this distribution as approximately symmetric with an outlier to the right.

\warn{Not all outliers warrant removal from your sample.}

\vspace{-12pt}
\warn{Don't let outliers completely influence how you define the shape of a distribution.}



\section{Comparing the Median and Mean} \label{sect:MeanMedian}
As mentioned previously, numerical measures will be used to describe the center and dispersion of a distribution. However, which values should be used? Should one use the mean or the median as a measure of center? Should one use the IQR or the standard deviation as a measure of dispersion? Which measures are used depend on how the measures respond to skew and the presence of outliers. Thus, before stating a rule for which measures should be used, a fundamental difference among the measures discussed in \modref{chap:UnivEDAQuant1} is explored here.

The following discussion is focused on comparing the mean and the median. However, note that the IQR is fundamentally linked to the median (i.e., to find the IQR, the median must first be found) and the standard deviation is fundamentally linked to the mean (i.e., to find the standard deviation, the mean must first be found). Thus, \textbf{the median and IQR will always be used together to measure center and dispersion, as will the mean and standard deviation.}

The mean and median measure center in different ways. The median balances the number of individuals smaller and larger than it. The mean, on the other hand, balances the sum of the distances from it to all points smaller than it and the sum of the distances from it to all points greater than it. Thus, the median is primarily concerned with the \textbf{position} of the value rather than the value itself, whereas the mean is very much concerned about the \textbf{values} for each individual (i.e., the values are used to find the ``distance'' from the mean).

\warn{The actual values of the data (beyond ordering the data) are not considered when calculating the median; whereas the actual values are very much considered when calculating the mean.}

A plot of the Richter scale data against the corresponding ordered individual number is shown in \figref{fig:MeanMedianComp1}-Left.\footnote{This is a rather non-standard graph but it is useful for comparing how the mean and median measure the center of the data.}  The median (blue line) is found by locating the middle position on the individual number axis and then finding the corresponding Richter scale value (move right until the point is intercepted and then move down to the x-axis). The vertical blue line represents the median, and it can be seen that it has the same \textbf{number} of individuals (i.e., points) below it as above it. In contrast, the mean finds the Richter scale value that has the same total distance to values below it as total distance to values above it. In other words, the mean is the vertical red line so that the total \textbf{length} of the horizontal dashed red lines is the same to the left as it is to the right. Thus, the median balances the number of individuals above and below the median, whereas the mean balances the difference in values above and below the mean.

<<MeanMedianComp1, echo=FALSE, out.width='.45\\linewidth', fig.cap="Plot of the individual number versus Richter scale values for the original earthquake data (\\textbf{Left}) and the earthquake data with an extreme outlier (\\textbf{Right}). The median value is shown as a blue vertical line and the mean value is shown as a red vertical line. Differences between each individual value and the mean value are shown with horizontal red lines.">>=
plot(EQ,1:length(EQ),pch=16,ylab="Individual Number",xlab="Richter Scale Value",xaxt="n",yaxt="n",ylim=c(0,16))
axis(1,c(5.5,6.0,8.0))
axis(2,seq(0,15,5))
text(5.15,8.7,"MP=",col="blue",xpd=TRUE)
text(5.15,7.5,"8",col="blue",xpd=TRUE)
lines(c(0,EQ[8]),c(8,8),lwd=2,lty=2,col="blue")
lines(c(EQ[8],EQ[8]),c(8,-1),lwd=2,lty=2,col="blue")
text(EQ[8],-1.3,"Median=7.10",xpd=TRUE,col="blue")
avg <- mean(EQ)
abline(v=avg,lwd=2,lty=2,col="red")
text(avg,-2.7,"Mean=7.07",xpd=TRUE,col="red")
for (i in 1:length(EQ)) {
  lines(c(EQ[i],avg),c(i,i),lwd=1.5,lty=3,col="red")
}

EQ1 <- c(EQ,19)
plot(EQ1,1:length(EQ1),pch=19,ylab="Individual Number",xlab="Richter Scale Value",xaxt="n",ylim=c(0,16))
axis(1,c(12,14,16,18))
axis(2,seq(0,15,5))
med<-7.2
text(3.5,8.7,"MP=",col="blue",xpd=TRUE)
text(3.5,7.5,"8.5",col="blue",xpd=TRUE)
lines(c(0,med),c(8.5,8.5),lwd=2,lty=2,col="blue")
lines(c(med,med),c(8.5,-1),lwd=2,lty=2,col="blue")
text(med,-1.3,"Median=7.20",xpd=TRUE,col="blue")
avg <- mean(EQ1)
abline(v=avg,lwd=2,lty=2,col="red")
text(avg,-2.7,"Mean=7.81",xpd=TRUE,col="red")
for (i in 1:length(EQ1)) {
  lines(c(EQ1[i],avg),c(i,i),lwd=1.5,lty=3,col="red")
}
@

\warn{The mean balances the distance to individuals above and below the mean. The median balances the number of individuals above and below the median.}

\vspace{-12pt}
\warn{The sum of all differences between individual values and the mean (as properly calculated) equals zero.}

The mean and median differ in their sensitivity to outliers (\figref{fig:MeanMedianComp1}-Right). For example, suppose that an incredible earthquake with a Richter Scale value of 19.0 was added to the earthquake data set. With this additional individual, the median increases from 7.1 to 7.2, but the mean increases from 7.1 to 7.8. The outlier affects the value of the mean more than it affects the value of the median because of the way that each statistic measures center. The mean will be pulled towards an outlier because it must ``put'' many values on the ``side'' of the mean away from the outlier so that the sum of the differences to the larger values and the sum of the differences to the smaller values will be equal. Thus, the outlier in this example creates a large difference to the right of the mean so the mean has to ``move'' to the right to make this difference smaller, move more individuals to the left side of the mean, and increase the differences of individuals to the left of the mean to balance this one large individual. The median on the other hand will simply ``put'' one more individual on the side opposite of the outlier because it balances the number of individuals on each side of it. Thus, the median has to move very little to the right to accomplish this balance.

\warn{The mean is more sensitive (i.e., changes more) to outliers than the median; it will be ``pulled'' towards the outlier more than the median.}

The shape of the distribution, even if outliers are not present, also has an effect on the values of the mean and median as depicted in \figref{fig:MeanMedianShape}. If a distribution is perfectly symmetric, then the median and mean (along with the mode) will be identical. If the distribution is approximately symmetric, then the median and mean will be approximately equal. If the distribution is right-skewed, then the mean will be greater than the median. Finally, if the distribution is left-skewed, then the mean will be less than the median.

<<MeanMedianShape, echo=FALSE, out.width='.3\\linewidth', fig.cap="Three differently shaped histograms with vertical lines superimposed at the median (M; blue lines) and the mean ($\\bar{x}$; red lines).">>=
par(mar=c(4,1,1,1),mgp=c(3,0.4,0),yaxs="i",las=1,tcl=-0.2)
brks <- seq(0,1,0.1)
hist(s2,main="",xlab="X",xaxt="n",yaxt="n",breaks=brks,col="gray90")
s.avg <- mean(s2)
s.med <- median(s2)
abline(v=s.avg,lwd=2,lty=3,col="red")
abline(v=s.med,lwd=2,lty=3,col="blue")
text(s.med,-7,"M",col="blue",xpd=TRUE,cex=1.5)
text(s.avg,-18,expression(bar(x)),col="red",xpd=TRUE,cex=1.5)

hist(r1,xlim=c(0,0.9),main="",xlab="X",xaxt="n",yaxt="n",breaks=brks,col="gray90")
r.avg <- mean(r1)
r.med<-median(r1)
abline(v=r.avg,lwd=2,lty=3,col="red")
abline(v=r.med,lwd=2,lty=3,col="blue")
text(r.med,-10,"M",col="blue",xpd=TRUE,cex=1.5)
text(r.avg,-24,expression(bar(x)),col="red",xpd=TRUE,cex=1.5)

hist(l1,xlim=c(0.1,1),main="",xlab="X",xaxt="n",yaxt="n",breaks=brks,col="gray90")
l.avg <- mean(l1)
l.med<-median(l1)
abline(v=l.avg,lwd=2,lty=3,col="red")
abline(v=l.med,lwd=2,lty=3,col="blue")
text(l.med,-9,"M",col="blue",xpd=TRUE,cex=1.5)
text(l.avg,-23,expression(bar(x)),col="red",xpd=TRUE,cex=1.5)
@

\warn{The mean and median are equal for symmetric distributions.}

\vspace{-12pt}
\warn{The mean is pulled towards the long tail of a skewed distribution. Thus, the mean is greater than the median for right-skewed distributions and the mean is less than the median for left-skewed distributions.}

As shown above, the mean and median measure center in different ways. The question now becomes ``which measure of center is better?''  The median is a ``better'' measure of center when outliers are present. In addition, the median gives a better measure of a typical individual when the data are skewed. Thus, in this course, the median is used when outliers are present or the distribution of the data is skewed. If the distribution is symmetric, then the purpose of the analysis will dictate which measure of center is ``better.''  However, in this course, use the mean when the data are symmetric or, at least, not strongly skewed.

\warn{Describe center with the median if outliers are present or the data are skewed; use the mean if the data are symmetric and no outliers are present.}


\section{Overall Summaries}

Finally, the IQR should be chosen as the measure of dispersion when the median is used as the measure of center because they are conceptually related (both rely on position rather than actual value).

The standard deviation has three important characteristics:
\begin{Enumerate}
  \item $s \geq$ 0 ($s$=0 only if there is no dispersion; i.e., all values are the same).
  \item $s$ is strongly influenced by outliers.
  \item $s$ is inflated for skewed distributions (similar to the mean).
\end{Enumerate}
The final two characteristics are a result of the standard deviation being computed from the \textbf{values}, rather than the position, of the individuals (as is the mean). The argument here is the same as it was for the mean. In fact, it should be obvious that the mean and standard deviation are conceptually linked (i.e., they both require the actual values and the mean is within the standard deviation calculation).


Overall numerical summaries come from considering the relationship between measures of center and dispersion. From the previous section it was seen that the standard deviation and mean are conceptually linked, as are the median and IQR. Indeed, the linked measure of center must be computed first in both dispersion calculations. Thus, if the mean is used to measure center, then the standard deviation must be used to measure dispersion. Similarly, if the median is used to measure center, then the IQR must be used to measure dispersion.\footnote{Recall that the range will never be used by itself.}


\section{Example Interpretations}
While most of the previous sections focused on how to construct various graphs and numerical summaries, the most important aspect of this module is that you can make appropriate interpretations for an EDA from the summary results. For quantitative data, an appropriate EDA consists of identifying the shape, center, dispersion, and outliers for the variable. For categorical data, an appropriate EDA consists of identifying the major characteristics among the categories. Below, I model properly constructed EDAs for the mouse consumption data and two new data sets.

\subsubsection{Mouse Consumption Example}
\begin{quote}
\textit{Construct a proper EDA for the following situation and data -- `The  following measurements \tabrefp{tab:MouseData} are of the consumption of water in one hour by mice in a laboratory setting.'}
\end{quote}
\vspace{-12pt}

<<echo=FALSE, results='hide'>>=
mstat <- Summarize(mc,digits=2)
@
Mouse water consumption is approximately symmetric without any outliers present \figrefp{fig:MouseHist2}. The center of the distribution is best measured by the mean, which is \Sexpr{formatC(mstat["mean"],format="f",digits=2)} ml \tabrefp{tab:MouseStats}. The range of water consumption by the mice in the sample is from \Sexpr{formatC(mstat["min"],format="f",digits=1)} to \Sexpr{formatC(mstat["max"],format="f",digits=1)} ml while the dispersion as measured by the standard deviation is \Sexpr{formatC(mstat["sd"],format="f",digits=2)} ml \tabrefp{tab:MouseStats}. I chose to use the mean and standard deviation because the data were symmetric with no outliers. [\textit{NOTE: 1) use of units, 2) reference to the figure and table, 3) labeling of the figure and table, 4) median and IQR were not discussed as I chose to use the mean and standard deviation, 5) the range was not used alone as a measure of dispersion, 6) the explanation for why the mean and standard deviation were used rather than the median and IQR, and 7) R code was provided.}]

<<MouseStats, results='asis', echo=FALSE>>=
mstat1 <- matrix(mstat,nrow=1)
colnames(mstat1) <- names(mstat)
print(xtable(mstat1,digits=2,caption="Descriptive statistics of mouse water consumption.","tab:MouseStats"),caption.placement="top",include.rownames=FALSE)
@

\begin{minipage}{\textwidth}
R Appendix:
<<eval=FALSE, prompt=FALSE>>=
setwd("c:/data/")
mc <- read.csv("MouseData.csv")
str(mc)
Summarize(~consump,data=mc,digits=2)
hist(~consump,data=mc,xlab="Water Consumption (mm)")
@
\end{minipage}

\subsubsection{Crayfish Temperature Selection}
\begin{quote}
\textit{\cite{Peck1985} examined the temperature selection of dominant and subdominant crayfish (\textit{Orconectes virilis}) together in an artificial stream. The temperature ($^{o}$C) selection by the dominant crayfish in the presence of subdominant crayfish in these experiments was recorded below. Thoroughly describe all aspects of the distribution of selected temperatures.}
\end{quote}

<<results='asis', echo=FALSE>>=
CT <- c(30,26,26,26,25,25,25,25,25,24,24,24,24,24,24,23,23,23,23,22,22,22,22,21,21,21,20,20,19,19,18,16)
CTx <- xtable(matrix(CT,nrow=2,byrow=TRUE),digits=0)
print(CTx,floating=FALSE,include.rownames=FALSE,include.colnames=FALSE,hline.after=NULL)
cstat <- Summarize(CT,digits=2)
@

The shape of temperatures selected by the dominant crayfish is slightly left-skewed \figrefp{fig:CrayfishTempHist} with a possible weak outlier at the maximum value of \Sexpr{formatC(cstat["max"],format="f",digits=0)}$^{o}$C \tabrefp{tab:CrayfishTempStats}. The center is best measured by the median, which is \Sexpr{formatC(cstat["median"],format="f",digits=0)}$^{o}$C \tabrefp{tab:CrayfishTempStats} and the dispersion is best measured by the IQR, which is from \Sexpr{formatC(cstat["Q1"],format="f",digits=0)} to \Sexpr{formatC(cstat["Q3"],format="f",digits=0)}$^{o}$C \tabrefp{tab:CrayfishTempStats}. I used the median and IQR because of the (combined) skewed shape and outlier present.

<<CrayfishTempHist, echo=FALSE, fig.cap="Histogram of crayfish temperature preferences.">>=
hist(~CT,xlab="Preferred Temperature",ylab="Frequency of Crayfish",w=2)
@

<<CrayfishStats, results='asis', echo=FALSE>>=
cstat1 <- matrix(cstat,nrow=1)
colnames(cstat1) <- names(cstat)
print(xtable(cstat1,digits=2,caption="Descriptive statistics of crayfish temperature preferences.","tab:CrayfishTempStats"),caption.placement="top",include.rownames=FALSE)
@

\begin{minipage}{\textwidth}
R Appendix:
<<eval=FALSE, prompt=FALSE>>=
setwd("c:/data/")
cray <- read.csv("Crayfish.csv")
str(cray)
hist(~temp,data=cray,xlab="Preferred Temperature",ylab="Frequency of Crayfish",w=2)
Summarize(~temp,data=cray,digits=2)
@
\end{minipage}

\newpage
\begin{exsection}
  \item \label{revex:quEDABoxLeft} What is the shape of the left boxplot below? \ansref{ans:quEDABoxLeft}
<<BoxplotQuest, echo=FALSE, results='hide', include=FALSE, fig.width=10.5, fig.height=3.5, fig.keep='last'>>=
par(mar=c(1,1,1,1),mgp=c(2.1,0.4,0),las=1,tcl=-0.2)
set.seed(12489)
d1 <- rbeta(100,10,1)
d2 <- rbeta(100,1,10)
d3 <- rbeta(100,16,15)
d1 <- d1-mean(d1)
d2 <- d2-mean(d2)
d3 <- d3-mean(d3)
bp <- data.frame(d=c(d1,d2,d3),g=factor(rep(c("A","B","C"),each=100)))
boxplot(d~g,data=bp,main="",xlab="",ylab="",xaxt="n",yaxt="n")
@
\begin{center}
  \includegraphics[width=4in]{Figs/BoxplotQuest-1}
\end{center}

  \item \label{revex:quEDABoxRight} What is the shape of the middle boxplot above? \ansref{ans:quEDABoxRight}
  \item \label{revex:quEDABoxSym} What is the shape of the right boxplot above? \ansref{ans:quEDABoxSym}
  \item \label{revex:quEDALSkewCtr} If the distribution is skewed left, which measure should you generally use to measure center? \ansref{ans:quEDALSkewCtr}
  \item \label{revex:quEDARSkewCtr} Which measure of center should you generally use for a right-skewed distribution? \ansref{ans:quEDARSkewCtr}
  \item \label{revex:quEDASymCtr} Which measure of center should you generally use for a symmetric distribution? \ansref{ans:quEDASymCtr}
  \item \label{revex:quEDASymDisp} Which measure of dispersion should you generally use for a symmetric distribution? \ansref{ans:quEDASymDisp}
  \item \label{revex:quEDALSkewDisp} Which measure of dispersion should you generally use for a left-skewed distribution? \ansref{ans:quEDALSkewDisp}
  \item \label{revex:quEDARSkewDisp} Which measure of dispersion should you generally use for a right-skewed distribution? \ansref{ans:quEDARSkewDisp}
  \item \label{revex:quEDAQShape1} Is Q3-Q2 less than, approximately equal to, or greater than Q2-Q1 if the data are left-skewed? \ansref{ans:quEDAQShape1}
  \item \label{revex:quEDAQShape2} What is the shape of the distribution if Q3-Q2 is greater than Q2-Q1? \ansref{ans:quEDAQShape2}
\end{exsection}

\begin{exsection}
  \item \label{revex:quEDALSkew} What is a distribution with a long left-tail called? \ansref{ans:quEDALSkew}
  \item \label{revex:quEDARSkew} What is a distribution with a long right-tail called? \ansref{ans:quEDARSkew}
  \item \label{revex:quEDALSkewg} What is the shape of the distribution on the left below? \ansref{ans:quEDALSkewg}

<<HistQuest, echo=FALSE, results='hide', include=FALSE, fig.width=10.5, fig.height=3.5, fig.keep='last'>>=
par(mar=c(1,1,1,1),mgp=c(2.1,0.4,0),mfrow=c(1,3),las=1,tcl=-0.2)
set.seed(12489)
hist(rbeta(100,6,1),main="",xlab="",ylab="",xaxt="n",yaxt="n",col="gray90")
hist(rbeta(100,1,6),main="",xlab="",ylab="",xaxt="n",yaxt="n",col="gray90")
hist(rbeta(100,6,5),main="",xlab="",ylab="",xaxt="n",yaxt="n",col="gray90")
@
\begin{center}
  \includegraphics[width=5in]{Figs/HistQuest-1}
\end{center}
  \item \label{revex:quEDASymg} What is the shape of the distribution in the center above? \ansref{ans:quEDASymg}
  \item \label{revex:quEDARSkewg} What is the shape of the distribution on the right above? \ansref{ans:quEDARSkewg}
  \item \label{revex:quEDAlead} Comment on the shape and presence of outliers in \figref{fig:KreherParkPbhist}. \ansref{ans:quEDAlead}
\end{exsection}



\begin{exsection}
  \item \label{revex:quEDALSkewMM}Is the mean less than, approximately equal to, or greater than the median for the distribution shown in Exercise \ref{revex:quEDALSkewg}? \ansref{ans:quEDALSkewMM}
  \item \label{revex:quEDAAsymMM}Is the mean less than, approximately equal to, or greater than the median for the distribution shown in Exercise \ref{revex:quEDASymg}? \ansref{ans:quEDAAsymMM}
  \item \label{revex:quEDARSkewMM}Is the mean less than, approximately equal to, or greater than the median for the distribution shown in Exercise \ref{revex:quEDARSkewg}? \ansref{ans:quEDARSkewMM}
  \item \label{revex:quEDARatio} Is the mean divided by the median less than 1, equal to 1, or greater than 1 for a symmetric distribution? \ansref{ans:quEDARatio}
  \item \label{revex:quEDABruleMM} From your calculation of the mean and median in Review Exercise  \ref{revex:quEDABrule} do you expect the histogram to be left-skewed, approximately symmetric, or right-skewed? \ansref{ans:quEDABruleMM}
  \item \label{revex:quEDAWIcMM} From your calculation of the mean and median in Review Exercise \ref{revex:quEDAWIc} do you expect the histogram to be left-skewed, approximately symmetric, or right-skewed? \ansref{ans:quEDAWIcMM}
\end{exsection}



\begin{exsection}
  \item \label{revex:quEDACP} \rhw{} Construct a proper EDA for the creatine phosphokinase data presented in Exercise \ref{revex:quEDACreatPhosph}. Make sure to defend your choice of numerical summaries. \ansref{ans:quEDACP}
  \item \label{revex:quEDADJTI} \rhw{} \hspace{12pt} The Dow Jones Travel Index tracks the cost of hotel and car-rental rates in 20 major cities. For its May 7, 1996, survey the following rates were given for the 20 cities: 152, 180, 167, 119, 115, 113, 119, 135, 140, 126, 114, 133, 205, 104, 149, 124, 127, 161, 106, and 179. Thoroughly describe the distribution of these data. [\textit{Note: You can use fewer than the ideal number of bars on your histogram because the sample size is so small in this situation.}] \ansref{ans:quEDADJTI}
  \item \label{revex:quEDAZoo2} \rhw{} The data in \href{https://raw.githubusercontent.com/droglenc/NCData/master/Zoo2.csv}{Zoo2.csv} contains the physical size (in acres) of a sample of zoos from around the United States. Perform a univariate EDA on the \var{size} variable. \ansref{ans:quEDAZoo2}
\end{exsection}
